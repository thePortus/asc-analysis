{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Witness Networks\n",
    "\n",
    "[David J. Thomas](mailto:dave.a.base@gmail.com), [thePortus.com](http://thePortus.com)<br />\n",
    "Instructor of Ancient History and Digital Humanities,<br />\n",
    "Department of History,<br />\n",
    "[University of South Florida](https://github.com/usf-portal)\n",
    "\n",
    "---\n",
    "\n",
    "## This workbook will...\n",
    "\n",
    "* Use the `networkx` module to analyze witnesses in the charters\n",
    "* Calculate network statistics like degree, betweeness centrality, community detection, and more\n",
    "* Export the network with statistics for use elsewhere in programs like Gephi\n",
    "* Visualize the network as a whole and in parts\n",
    "* Attempt to identify major figures at different levels of the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1) Import Module Dependencies\n",
    "\n",
    "The cell below loads all other Python packages needed. You **must** run this before any other cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import sqlalchemy as sql\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import networkx as nx\n",
    "import community\n",
    "import matplotlib.pyplot as plt\n",
    "import dhelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) (Re)declare Database Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sql.create_engine('sqlite:///charters.db', encoding='utf-8')\n",
    "Base = declarative_base()\n",
    "    \n",
    "\n",
    "class Charter(Base):\n",
    "    __tablename__ = 'charters'\n",
    "\n",
    "    id = sql.Column(sql.String, primary_key=True)\n",
    "    description = sql.Column(sql.String)\n",
    "    sawyer = sql.Column(sql.Integer)\n",
    "    birch = sql.Column(sql.Integer)\n",
    "    kemble = sql.Column(sql.Integer)\n",
    "    british_academy = sql.Column(sql.String)\n",
    "    source_used = sql.Column(sql.String)\n",
    "    archive = sql.Column(sql.String)\n",
    "    language = sql.Column(sql.String)\n",
    "    date = sql.Column(sql.Integer)\n",
    "    scholarly_date = sql.Column(sql.String)\n",
    "    scholarly_date_low = sql.Column(sql.Integer)\n",
    "    scholarly_date_high = sql.Column(sql.Integer)\n",
    "    scholarly_date_avg = sql.Column(sql.Float)\n",
    "    text = sql.Column(sql.Text)\n",
    "    notes = sql.Column(sql.Text)\n",
    "    asc_source = sql.Column(sql.String)\n",
    "    pase_source = sql.Column(sql.String)\n",
    "    pase_witnesses = sql.Column(sql.String)\n",
    "    \n",
    "    witnesses = sql.orm.relationship('Person', secondary='charter_witnesses', back_populates='charters')\n",
    "    \n",
    "    @property\n",
    "    def record(self):\n",
    "        \"\"\"Gets entry data in dictionary format.\"\"\"\n",
    "        return {\n",
    "            'id': self.id,\n",
    "            'label': self.id,\n",
    "            'sawyer': self.sawyer,\n",
    "            'birch': self.birch,\n",
    "            'kemble': self.kemble,\n",
    "            'british_academy': self.british_academy,\n",
    "            'source_used': self.source_used,\n",
    "            'archive': self.archive,\n",
    "            'language': self.language,\n",
    "            'date': self.date,\n",
    "            'scholarly_date': self.scholarly_date,\n",
    "            'scholarly_date_low': self.scholarly_date_low,\n",
    "            'scholarly_date_high': self.scholarly_date_high,\n",
    "            'scholarly_date_avg': self.scholarly_date_avg,\n",
    "            'text': self.text,\n",
    "            'notes': self.notes,\n",
    "            'asc_source': self.asc_source,\n",
    "            'pase_source': self.pase_source,\n",
    "            'pase_witnesses': self.pase_witnesses\n",
    "        }\n",
    "    \n",
    "    def num_common_witnesses(self, other_charter):\n",
    "        \"\"\"Checks self and other_charter for the number of witnesses that appear in both charters.\"\"\"\n",
    "        total_counter = 0\n",
    "        for witness in self.witnesses:\n",
    "            for other_witness in other_person.witnesses:\n",
    "                if witness.id == other_witness.id:\n",
    "                    total_counter += 1\n",
    "        return total_counter\n",
    "                    \n",
    "    \n",
    "class Person(Base):\n",
    "    __tablename__ = 'people'\n",
    "    \n",
    "    id = sql.Column(sql.String, primary_key=True)\n",
    "    description = sql.Column(sql.String)\n",
    "    link = sql.Column(sql.String)\n",
    "    \n",
    "    charters = sql.orm.relationship('Charter', secondary='charter_witnesses', back_populates='witnesses')\n",
    "    \n",
    "    @property\n",
    "    def record(self):\n",
    "        \"\"\"Gets entry data in dictionary format.\"\"\"\n",
    "        return {\n",
    "            'id': self.id,\n",
    "            'label': self.id + ': ' + self.description,\n",
    "            'link': self.link\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def earliest_appearance(self):\n",
    "        \"\"\"Returns the date of the earliest charter features said person.\"\"\"\n",
    "        earliest_charter = None\n",
    "        for charter in self.charters:\n",
    "            if not earliest_charter:\n",
    "                earliest_charter = charter.scholarly_date_avg\n",
    "            else:\n",
    "                if charter.scholarly_date_avg < earliest_charter:\n",
    "                    earliest_charter = charter.scholarly_date_avg\n",
    "        return earliest_charter\n",
    "    \n",
    "    def num_coappearances(self, other_person):\n",
    "        \"\"\"Checks the number of times this person appears in the same charters as other_person\"\"\"\n",
    "        total_counter = 0\n",
    "        for charter in self.charters:\n",
    "            for other_charter in other_person.charters:\n",
    "                if charter.id == other_charter.id:\n",
    "                    total_counter += 1\n",
    "        return total_counter\n",
    "\n",
    "    \n",
    "class CharterWitness(Base):\n",
    "    __tablename__ = 'charter_witnesses'\n",
    "    charter_id = sql.Column(sql.String, sql.ForeignKey('charters.id'), primary_key=True) \n",
    "    person_id = sql.Column(sql.String, sql.ForeignKey('people.id'), primary_key=True)\n",
    "    role = sql.Column(sql.String)\n",
    "    link = sql.Column(sql.String)\n",
    "    \n",
    "    @property\n",
    "    def record(self):\n",
    "        \"\"\"Gets entry data in dictionary format.\"\"\"\n",
    "        return {\n",
    "            'charter_id': self.charter_id,\n",
    "            'person_id': self.person_id,\n",
    "            'label': self.role,\n",
    "            'link': self.link\n",
    "        }\n",
    "\n",
    "\n",
    "print('Database Configured Successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Build Co-Appearing Witness Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to open a session with the local database, get every witness, then close the connection\n",
    "session = sessionmaker(bind=engine)()\n",
    "witnesses = session.query(Person)\n",
    "session.close()\n",
    "\n",
    "print('Building network graph...', end='')\n",
    "# create an empty networkx graph\n",
    "witness_network = nx.Graph(\n",
    "    label='',\n",
    "    link=None,\n",
    "    weight=1,\n",
    "    type='Undirected',\n",
    "    community=None,\n",
    "    degree=0,\n",
    "    degree_centrality=0,\n",
    "    betweeness_centrality=0,\n",
    "    eigenvector_centrality=0,\n",
    "    closeness_centrality=0,\n",
    "    harmonic_centrality=0,\n",
    ")\n",
    "\n",
    "# populate the nodes with each witness record\n",
    "for person in witnesses:\n",
    "    witness_network.add_node(person.id, **person.record)\n",
    "\n",
    "counter = 0\n",
    "# to build edges, we need to compare every witness against each other for the number of times they appear\n",
    "for index, person in enumerate(witnesses):\n",
    "    for other_person in witnesses[index + 1:]:\n",
    "        counter += 1\n",
    "        if counter % 50000 == 0:\n",
    "            print('.', end='')\n",
    "        num_coappearances = person.num_coappearances(other_person)\n",
    "        # only add an edge if they actually appeared together\n",
    "        if num_coappearances > 0:\n",
    "            witness_network.add_edge(\n",
    "                person.id,\n",
    "                other_person.id,\n",
    "                label='{} -> {}'.format(person.id, other_person.id),\n",
    "                weight=person.num_coappearances(other_person),\n",
    "                type='Undirected'\n",
    "            )\n",
    "\n",
    "print('\\n\\nFinished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Crunch Network Statistics and Export Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crunch_network(network):\n",
    "    print('Crunching various network statistics (takes awhile)...\\n')\n",
    "    results = {\n",
    "        'degree': {}, 'community': {}, 'degree_centrality': {}, 'betweeness_centrality': {},\n",
    "        'eigenvector_centrality': {}, 'closeness_centrality': {}, 'harmonic_centrality': {}\n",
    "    }\n",
    "    # degrees and community\n",
    "    print('Degrees...', end='')\n",
    "    results['degree'] = nx.degree(witness_network)\n",
    "    print(' Done!\\nCommunity detection with best partition...', end='')\n",
    "    results['community'] = community.best_partition(witness_network)\n",
    "    # centralities\n",
    "    print(' Done!\\nDegree centrality...', end='')\n",
    "    results['degree_centrality'] = nx.degree_centrality(witness_network)\n",
    "    print(' Done!\\nBetweeness (shortest-path) centrality...', end='')\n",
    "    results['betweeness_centrality'] = nx.betweenness_centrality(witness_network)\n",
    "    print(' Done!\\nEigenvector centrality...', end='')\n",
    "    results['eigenvector_centrality'] = dict(nx.eigenvector_centrality(witness_network))\n",
    "    print(' Done!\\nCloseness centrality...', end='')\n",
    "    results['closeness_centrality'] = nx.closeness_centrality(witness_network)\n",
    "    print(' Done!\\nHarmonic centrality...', end='')\n",
    "    results['harmonic_centrality'] =  nx.harmonic_centrality(witness_network)\n",
    "    print(' Done!\\n\\nFinished calculating network statistics.')\n",
    "    # now take result dicts and feed them back into nodes as attributes\n",
    "    for attribute_name in results.keys():\n",
    "        attribute_results = results[attribute_name]\n",
    "        for node_id in network.nodes():\n",
    "            new_node_stat = attribute_results[node_id]\n",
    "            network.nodes[node_id][attribute_name] = new_node_stat\n",
    "    return network\n",
    "\n",
    "\n",
    "witness_network = crunch_network(witness_network)\n",
    "print('Exporting network with calculated statistics to export/witness_network.gexf')\n",
    "nx.write_gexf(witness_network, '../export/witness_network.gexf')\n",
    "print('Exported network successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Visualize Entire Witness Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_network(network, with_labels=False):\n",
    "    node_size_map = [network.nodes[node]['betweeness_centrality'] * 3000 for node in network.nodes()]\n",
    "    node_color_map = [network.nodes[node]['community'] for node in network.nodes()]\n",
    "    options = {\n",
    "        'node_color': node_color_map,\n",
    "        'node_size': node_size_map,\n",
    "        'width': 0.1,\n",
    "        'alpha': 0.5,\n",
    "        'with_labels': with_labels\n",
    "    }\n",
    "    print('Generating network preview...')\n",
    "    nx.draw(network, pos=nx.spring_layout(network, k=0.05, scale=1), **options)\n",
    "    plt.draw()\n",
    "    return True\n",
    "\n",
    "\n",
    "print('Entire Witness Network')\n",
    "draw_network(witness_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Finding Key Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a) Listing Top People by Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_nodes_by_attribute(network, attribute_name):\n",
    "    totals = {}\n",
    "    # build a key/val dict from id/val of node\n",
    "    for node in network.nodes():\n",
    "        totals[node] = network.nodes[node][attribute_name]\n",
    "    # sort into ordered list of tuples with id/val and return\n",
    "    return [(key, totals[key]) for key in sorted(totals, key=totals.get, reverse=True)]\n",
    "\n",
    "\n",
    "def print_top_nodes_by_attribute(network, attribute_name, print_name, limit=5):\n",
    "    print('----- {} -----'.format(print_name))\n",
    "    counter = 0\n",
    "    for node_id, val in order_nodes_by_attribute(network, attribute_name)[0:4]:\n",
    "        counter += 1\n",
    "        node_link = network.nodes[node_id]['link']\n",
    "        print('{}.) {}: {}'.format(counter, node_id, node_link, val))\n",
    "\n",
    "\n",
    "attributes_to_print = [\n",
    "    ('degree', 'Degree'),\n",
    "    ('betweeness_centrality', 'Betweeness Centrality'),\n",
    "    ('degree_centrality', 'Degree Centrality'),\n",
    "    ('closeness_centrality', 'Closeness Centrality'),\n",
    "    ('eigenvector_centrality', 'Eigenvector Centrality'),\n",
    "    ('harmonic_centrality', 'Harmonic Centrality')\n",
    "]\n",
    "\n",
    "for attribute_name, print_name in attributes_to_print:\n",
    "    print_top_nodes_by_attribute(witness_network, attribute_name, print_name)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b) Looking into Individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_person(network, node_id):\n",
    "    link = network.nodes[node_id]['link']\n",
    "    pase_content = None\n",
    "    with dhelp.WebPage(link) as page_soup:\n",
    "        pase_content = page_soup\n",
    "    display(HTML(pase_content.get_text()))\n",
    "    return pase_content\n",
    "\n",
    "notable_persons = ['Alfred 8', 'Wulfred 6', 'Eadwulf 7', 'Ceolnoth 3', 'Æthelbald 4', 'Cenwealh 2', 'Offa 7']\n",
    "\n",
    "for notable_person in notable_persons:\n",
    "    print('---', notable_person)\n",
    "    lookup_person(witness_network, notable_person)\n",
    "\n",
    "print('Finished displaying persons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Looking into Sub-Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_community(network, community_num):\n",
    "    \"\"\"Returns a new network with only nodes/edges from a specified community\"\"\"\n",
    "    non_community_nodes = []\n",
    "    # perform full copy of network\n",
    "    subnetwork = network.copy()\n",
    "    # identify only the nodes to be keps\n",
    "    for node_id in subnetwork.nodes():\n",
    "        if subnetwork.nodes[node_id]['community'] != community_num:\n",
    "            non_community_nodes.append(node_id)\n",
    "    subnetwork.remove_nodes_from(non_community_nodes)\n",
    "    # make new subgraph with select nodes and crunch new stats\n",
    "    return crunch_network(subnetwork)\n",
    "\n",
    "\n",
    "print('Alfred the Great')\n",
    "alfred_community = get_community(witness_network, witness_network.nodes['Alfred 8']['community'])\n",
    "draw_network(alfred_community)\n",
    "\n",
    "for attribute_name, print_name in attributes_to_print:\n",
    "    print_top_nodes_by_attribute(alfred_community, attribute_name, print_name)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Offa of Mercia')\n",
    "offa_community = get_community(witness_network, witness_network.nodes['Offa 7']['community'])\n",
    "draw_network(offa_community, with_labels=True)\n",
    "\n",
    "for attribute_name, print_name in attributes_to_print:\n",
    "    print_top_nodes_by_attribute(offa_community, attribute_name, print_name)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
